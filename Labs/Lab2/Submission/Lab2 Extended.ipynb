{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Extended Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Method to parse the structure of an html page using package beautifulsoup.\n",
    "\n",
    "# The code looks for specific tags in the html structure and extracts the content\n",
    "\n",
    "def getArticleDetailsByUrl(url):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    \n",
    "    #soup.prettify()\n",
    "    \n",
    "    headline = soup.title.string\n",
    "    \n",
    "    subheadline = soup.head.find(\"meta\",attrs={\"name\":\"description\"}).get('content')\n",
    "\n",
    "    doc_body = ''\n",
    "    \n",
    "    if \"The Irish Times\" in soup.text:\n",
    "        \n",
    "        for body_p_tag in soup.article.find_all(\"p\", attrs={\"class\": \"no_name\"}):\n",
    "            \n",
    "            doc_body += body_p_tag.get_text() + \" \"\n",
    "\n",
    "    source = \"Other\"\n",
    "    try:\n",
    "        if \"irishtimes\" in url:\n",
    "            \n",
    "            source = \"IrishTimes\"\n",
    "            \n",
    "            body_p_tag = soup.article.find(\"div\", attrs={\"class\": \"last_updated\"}).find(\"p\")\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    first_sentence = doc_body.split(\".\")[0]\n",
    "\n",
    "    return [headline, subheadline, first_sentence, doc_body, source]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU Contest for Young Scientists features starc...</td>\n",
       "      <td>The top prizes in this year’s European Union C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior entrepreneurs encouraged to start real ...</td>\n",
       "      <td>A few years ago entrepreneur and multimilliona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New personal injury measures needed to reduce ...</td>\n",
       "      <td>A report has called for new guidelines for jud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Councils should buy vacant houses compulsorily...</td>\n",
       "      <td>A major programme of compulsory purchasing of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unemployment main driver for Spaniards moving ...</td>\n",
       "      <td>When Alvaro Cabello came to Ireland in 2012 it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Title  \\\n",
       "Article_ID                                                      \n",
       "1           EU Contest for Young Scientists features starc...   \n",
       "2           Junior entrepreneurs encouraged to start real ...   \n",
       "3           New personal injury measures needed to reduce ...   \n",
       "4           Councils should buy vacant houses compulsorily...   \n",
       "5           Unemployment main driver for Spaniards moving ...   \n",
       "\n",
       "                                                      Content  \n",
       "Article_ID                                                     \n",
       "1           The top prizes in this year’s European Union C...  \n",
       "2           A few years ago entrepreneur and multimilliona...  \n",
       "3           A report has called for new guidelines for jud...  \n",
       "4            A major programme of compulsory purchasing of...  \n",
       "5           When Alvaro Cabello came to Ireland in 2012 it...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "\n",
    "parser = feedparser.parse('http://www.irishtimes.com/cmlink/news-1.1319192')\n",
    "        \n",
    "i = int\n",
    "i = 1\n",
    "\n",
    "dataframe = pd.DataFrame({'Article_ID': [], 'Title': [], 'Content': []})\n",
    "    \n",
    "for item in parser['entries']:\n",
    "    article_url = item['link']\n",
    "    [ headline, subheadline, first_sentence, doc_body, source] = getArticleDetailsByUrl(article_url) \n",
    "    dataframe = dataframe.append({'Article_ID': int(i), 'Title': headline, 'Content': doc_body}, ignore_index=True)\n",
    "    i+=1\n",
    "    \n",
    "dataframe['Article_ID'] = dataframe.Article_ID.astype(int)\n",
    "dataframe.set_index('Article_ID', inplace=True)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'twitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-84007c27eb21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Import the necessary methods from \"twitter\" library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Please make sure twitter is installed: pip install twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOAuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwitterStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Variables that contains the user credentials to access Twitter API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'twitter'"
     ]
    }
   ],
   "source": [
    "# Using Twitter Search API to get public tweets from the past\n",
    "# Initiate the connection to Twitter REST API\n",
    "import json\n",
    "# Import the necessary methods from \"twitter\" library\n",
    "# Please make sure twitter is installed: pip install twitter\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "# ACCESS_TOKEN = 'YOUR ACCESS TOKEN\"'\n",
    "# ACCESS_SECRET = 'YOUR ACCESS TOKEN SECRET'\n",
    "# CONSUMER_KEY = 'YOUR API KEY'\n",
    "# CONSUMER_SECRET = 'ENTER YOUR API SECRET'\n",
    "ACCESS_TOKEN = '2839893905-pBXUzdrHCNXyjfPuBpSwxNbH1zyEpRaa2sXK0Jd'\n",
    "ACCESS_SECRET = 'eNtB7YTAfsMhPIQtKji8aQT7zQFpFfDPR2lQ89WKfgI1U'\n",
    "CONSUMER_KEY = 'ZqPrfLpc0znZlz3kW2a22VmUa'\n",
    "CONSUMER_SECRET = 'BHD19T0DmUV2XVvEhUAgvpXMx0nGfxevAtr53NbCd9jQjPyTqn'\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter = Twitter(auth=oauth)\n",
    "            \n",
    "# Search for latest 100 tweets about \"#analytics\"\n",
    "iterator = twitter.search.tweets(q='#analytics', result_type='recent', lang='en', count=100)\n",
    "#print(json.dumps(iterator, indent=4))\n",
    "\n",
    "file = open(\"twitter_search_100tweets.json\", \"w\") \n",
    "for tweet in iterator['statuses']:\n",
    "    #print(json.dumps(tweet))\n",
    "    file.write(json.dumps(tweet)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
